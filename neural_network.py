# -*- coding: utf-8 -*-
"""Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hemdsL9R92loUAp1rVbhFTxdbEWhNHsR

# Neural Network

## Importing libraries
"""

import pandas as pd
import numpy as np
import matplotlib as plt
import matplotlib.pyplot as plt
import tensorflow as tf

tf.__version__

"""## Importing dataset"""

dataset = pd.read_csv('/content/American Express User Exit.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

print(X)

"""# Encoding Categorical Data

## Gender Column : Label Encoding
"""

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
X[:, 2] = label_encoder.fit_transform(X[:, 2])

print(X)

"""## Geography Column : One Hot Encoding"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')
X = np.array(ct.fit_transform(X))

"""## Visualizing Clusters"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

"""## Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# ANN

## Initalisation
"""

ann = tf.keras.models.Sequential()

"""## Adding Input Layers and first hidden layer"""

ann.add(tf.keras.layers.Dense(units = 5 , activation = 'relu'))

"""## Adding second hidden layer"""

ann.add(tf.keras.layers.Dense(units = 5 , activation = 'relu'))

"""## Adding output layer"""

ann.add(tf.keras.layers.Dense(units = 5 , activation = 'relu'))

"""#ANN Training"""

# Example of a multi-class classification model
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
# Add your desired layers here...
model.add(Dense(2, activation='softmax'))  # Output layer for multi-class classification

from keras.models import Sequential
from keras.layers import Dense

# Step 1: Define your model
num_features = X_train.shape[1]  # Assuming X_train is your input data
model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(num_features,)))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='relu'))  # Output layer for binary classification

# Step 2: Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Step 3: Fit the model
model.fit(X_train, y_train, batch_size=32, epochs=120)

"""# Predictions

## single prediction
"""

from sklearn.preprocessing import StandardScaler
import numpy as np

# Assuming sc is your StandardScaler and ann is your trained model

# Sample input data (a single sample with 10 features)
input_data = np.array([0.0, 1.0, 0.0, 501, 32, 2, 0.0, 0,  4, 1, 5445501])

# Create a new StandardScaler instance and fit it on your current dataset
sc = StandardScaler()
sc.fit(X_train)  # Replace X_train with your training data

# Reshape the input data to have the correct shape (1, num_features)
input_data_reshaped = input_data.reshape(1, -1)

# Apply the scaler's transform to the reshaped input data
scaled_input = sc.transform(input_data_reshaped)

# Perform the prediction
prediction = ann.predict(scaled_input)

# If you want to check if the prediction is greater than 0.5
print(prediction > 0.5)

import numpy as np

y_pred = ann.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

# Reshape the y_test array to have one column
y_test_reshaped = y_test.reshape(-1, 1)

# Double-check the shapes of y_pred_binary and y_test_reshaped
print(y_pred_binary.shape)
print(y_test_reshaped.shape)

# Concatenate the reshaped arrays
concatenated = np.concatenate((y_pred_binary, y_test_reshaped), axis=1)

print(concatenated)

"""## Confusion Matrix"""

from keras.models import Sequential
from keras.layers import Dense

# Assuming you have a binary classification model named 'ann'

# Replace the last layer with a single unit and 'sigmoid' activation
ann.pop()  # Remove the current last layer
ann.add(Dense(1, activation='sigmoid'))  # Add a new output layer

# Compile the model after modifying the output layer
ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

from keras.models import Sequential
from keras.layers import Dense

# Step 1: Load or recreate your binary classification model
# Example: If you've already trained a model named 'ann', load it here
# Otherwise, recreate the model with the correct architecture and compile it

# Step 2: Ensure the last layer of the model is configured correctly
# For binary classification, use a single unit and 'sigmoid' activation
# Example:
ann = Sequential()
# Add your model layers here (input layer, hidden layers, etc.)
ann.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification
# Compile the model with the appropriate loss and metrics

# Step 3: Re-train your model if needed, ensuring you are using binary labels (0 or 1) for y_train

# Once you have the correct model predictions (y_pred) and labels (y_test) for binary classification, proceed to calculate the metrics:

from sklearn.metrics import confusion_matrix, accuracy_score

# Assuming you have the correct y_pred and y_test arrays
cm = confusion_matrix(y_test, (y_pred > 0.5).astype(int))
print(cm)

acs = accuracy_score(y_test, (y_pred > 0.5).astype(int))
print(acs)